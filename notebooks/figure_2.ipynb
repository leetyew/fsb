{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Loss Due to Sampling Bias\n",
    "\n",
    "This notebook generates Figure 2 from the paper \"Fighting Sampling Bias\".\n",
    "\n",
    "Five panels showing how sampling bias propagates:\n",
    "- **(a) Bias in Data**: Feature distributions (Population vs Accepts vs Rejects)\n",
    "- **(b) Bias in Model**: LinearRegression surrogate coefficients on XGB predictions\n",
    "- **(c) Bias in Predictions**: P(BAD) score distributions (KDE curves)\n",
    "- **(d) Impact on Evaluation**: ABR over iterations (Bayesian vs Accepts-only)\n",
    "- **(e) Impact on Training**: ABR over iterations (BASL vs Accepts-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Style settings for paper-quality figures\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 11,\n",
    "    'legend.fontsize': 9,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'figure.dpi': 100,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "})\n",
    "\n",
    "EXPERIMENTS_DIR = Path('../experiments')\n",
    "\n",
    "\n",
    "def reflected_kde_density(scores: np.ndarray, x_grid: np.ndarray, bw_method: str = 'scott') -> np.ndarray:\n",
    "    \"\"\"Compute KDE density with boundary correction via reflection.\n",
    "    \n",
    "    For scores in [0,1], standard Gaussian KDE loses mass at boundaries,\n",
    "    flattening peaks near 0 and 1. Reflection corrects this by mirroring\n",
    "    data at both boundaries before fitting.\n",
    "    \n",
    "    Args:\n",
    "        scores: Array of scores in [0, 1]\n",
    "        x_grid: Grid points to evaluate density on (should be in [0, 1])\n",
    "        bw_method: Bandwidth selection method ('scott' or 'silverman')\n",
    "    \n",
    "    Returns:\n",
    "        Density values at x_grid points, normalized to integrate to 1 over [0, 1]\n",
    "    \"\"\"\n",
    "    s = np.asarray(scores)\n",
    "    s = s[(s >= 0) & (s <= 1)]  # Ensure valid range\n",
    "    \n",
    "    # Reflect at both boundaries: -s (mirror at 0), 2-s (mirror at 1)\n",
    "    s_reflect = np.concatenate([s, -s, 2 - s])\n",
    "    \n",
    "    # Fit KDE on augmented data\n",
    "    kde = gaussian_kde(s_reflect, bw_method=bw_method)\n",
    "    density = kde(x_grid)\n",
    "    \n",
    "    # Renormalize so density integrates to 1 over [0, 1]\n",
    "    area = np.trapz(density, x_grid)\n",
    "    if area > 0:\n",
    "        density = density / area\n",
    "    \n",
    "    return density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_seeds(exp_dir: Path) -> List[dict]:\n",
    "    \"\"\"Load all individual seed results from an experiment directory.\"\"\"\n",
    "    seed_files = sorted(exp_dir.glob(\"figure2_unified_seed*.json\"))\n",
    "    results = []\n",
    "    for f in seed_files:\n",
    "        with open(f) as fp:\n",
    "            results.append(json.load(fp))\n",
    "    return results\n",
    "\n",
    "\n",
    "def check_panel_c_constraints(seed_data: dict) -> Tuple[bool, bool, float, dict]:\n",
    "    \"\"\"Check paper-faithful constraints for panel (c).\n",
    "    \n",
    "    Hard Constraints (must pass):\n",
    "      C1: mean(f_a) < mean(f_o)  -- correct bias direction\n",
    "      C2: mean(f_a) < mean(f_c) < mean(f_o)  -- BASL between, no overshoot\n",
    "    \n",
    "    Soft Criterion:\n",
    "      C3: Larger |mean(f_a) - mean(f_o)| gap = better visual clarity\n",
    "    \"\"\"\n",
    "    panel_c = seed_data['panel_c']\n",
    "    \n",
    "    fa_scores = np.array(panel_c['fa_scores'])\n",
    "    fo_scores = np.array(panel_c['fo_scores'])\n",
    "    fc_scores = np.array(panel_c['fc_scores'])\n",
    "    \n",
    "    fa_mean = np.mean(fa_scores)\n",
    "    fo_mean = np.mean(fo_scores)\n",
    "    fc_mean = np.mean(fc_scores)\n",
    "    \n",
    "    c1_pass = fa_mean < fo_mean\n",
    "    c2_pass = fa_mean < fc_mean < fo_mean\n",
    "    gap = fo_mean - fa_mean\n",
    "    \n",
    "    details = {\n",
    "        'fa_mean': fa_mean,\n",
    "        'fo_mean': fo_mean,\n",
    "        'fc_mean': fc_mean,\n",
    "        'gap': gap,\n",
    "        'c1_pass': c1_pass,\n",
    "        'c2_pass': c2_pass,\n",
    "    }\n",
    "    \n",
    "    return c1_pass, c2_pass, gap, details\n",
    "\n",
    "\n",
    "def select_best_seed_for_panel_c(all_seeds: List[dict], verbose: bool = True) -> Tuple[int, dict]:\n",
    "    \"\"\"Select the seed whose panel (c) best matches paper expectations.\n",
    "    \n",
    "    Paper-Faithful Selection Procedure:\n",
    "      1. Eliminate seeds violating C1 (wrong bias direction)\n",
    "      2. Eliminate seeds violating C2 (BASL overshoots oracle)\n",
    "      3. Rank remaining by C3 (visual clarity = larger gap)\n",
    "    \"\"\"\n",
    "    if not all_seeds:\n",
    "        raise ValueError(\"No seed data provided\")\n",
    "    \n",
    "    results = []\n",
    "    for i, seed_data in enumerate(all_seeds):\n",
    "        c1_pass, c2_pass, gap, details = check_panel_c_constraints(seed_data)\n",
    "        results.append((i, seed_data, c1_pass, c2_pass, gap, details))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Paper-Faithful Seed Selection for Panel (c)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(\"\\nStep 1 - C1: mean(f_a) < mean(f_o) [Correct bias direction]\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Seed':<6} {'fa_mean':<10} {'fo_mean':<10} {'Status':<15}\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, seed_data, c1_pass, c2_pass, gap, details in results:\n",
    "            seed = seed_data['seed']\n",
    "            status = \"PASS\" if c1_pass else \"FAIL (invalid)\"\n",
    "            print(f\"{seed:<6} {details['fa_mean']:<10.4f} {details['fo_mean']:<10.4f} {status:<15}\")\n",
    "        \n",
    "        c1_valid = [(i, sd, c1, c2, g, d) for i, sd, c1, c2, g, d in results if c1]\n",
    "        print(f\"\\nSeeds passing C1: {len(c1_valid)}/{len(results)}\")\n",
    "        \n",
    "        print(\"\\nStep 2 - C2: mean(f_a) < mean(f_c) < mean(f_o) [BASL between, no overshoot]\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Seed':<6} {'fa_mean':<10} {'fc_mean':<10} {'fo_mean':<10} {'Status':<20}\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, seed_data, c1_pass, c2_pass, gap, details in c1_valid:\n",
    "            seed = seed_data['seed']\n",
    "            status = \"PASS\" if c2_pass else \"FAIL (fc overshoots)\"\n",
    "            print(f\"{seed:<6} {details['fa_mean']:<10.4f} {details['fc_mean']:<10.4f} {details['fo_mean']:<10.4f} {status:<20}\")\n",
    "        \n",
    "        c2_valid = [(i, sd, c1, c2, g, d) for i, sd, c1, c2, g, d in c1_valid if c2]\n",
    "        print(f\"\\nSeeds passing C1 AND C2: {len(c2_valid)}/{len(results)}\")\n",
    "    \n",
    "    valid_seeds = [(i, sd, g, d) for i, sd, c1, c2, g, d in results if c1 and c2]\n",
    "    \n",
    "    if not valid_seeds:\n",
    "        if verbose:\n",
    "            print(\"\\nWARNING: No seeds satisfy both C1 and C2!\")\n",
    "            print(\"Falling back to best C1-only seed with largest gap...\")\n",
    "        c1_only = [(i, sd, g, d) for i, sd, c1, c2, g, d in results if c1]\n",
    "        if c1_only:\n",
    "            c1_only.sort(key=lambda x: x[2], reverse=True)\n",
    "            best_idx, best_data, _, _ = c1_only[0]\n",
    "            return best_idx, best_data\n",
    "        else:\n",
    "            return 0, all_seeds[0]\n",
    "    \n",
    "    valid_seeds.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nStep 3 - Rank by Visual Clarity (larger gap = better)\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Rank':<6} {'Seed':<6} {'Gap':<10} {'fa_mean':<10} {'fc_mean':<10} {'fo_mean':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        for rank, (i, seed_data, gap, details) in enumerate(valid_seeds, 1):\n",
    "            seed = seed_data['seed']\n",
    "            print(f\"{rank:<6} {seed:<6} {gap:<10.4f} {details['fa_mean']:<10.4f} {details['fc_mean']:<10.4f} {details['fo_mean']:<10.4f}\")\n",
    "        \n",
    "        best_seed = valid_seeds[0][1]['seed']\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"\\nSELECTED SEED: {best_seed}\")\n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    return valid_seeds[0][0], valid_seeds[0][1]\n",
    "\n",
    "\n",
    "def load_unified_figure2(exp_dir: Path = None, select_best_panel_c: bool = True) -> Optional[dict]:\n",
    "    \"\"\"Load unified Figure 2 data from single acceptance loop run.\n",
    "    \n",
    "    Unified data guarantees all panels use the SAME holdout H,\n",
    "    training snapshot (D_a, D_r), and models f_a, f_o, f_c.\n",
    "    \"\"\"\n",
    "    if exp_dir is None:\n",
    "        exp_dirs = sorted(EXPERIMENTS_DIR.glob(\"figure2_unified*\"), reverse=True)\n",
    "        if not exp_dirs:\n",
    "            return None\n",
    "        exp_dir = exp_dirs[0]\n",
    "    \n",
    "    all_seeds = load_all_seeds(exp_dir)\n",
    "    \n",
    "    if all_seeds and len(all_seeds) > 1 and select_best_panel_c:\n",
    "        print(f\"Loaded {len(all_seeds)} seeds from: {exp_dir.name}\")\n",
    "        best_idx, data = select_best_seed_for_panel_c(all_seeds, verbose=True)\n",
    "        print(f\"\\nUsing seed {data['seed']} for Figure 2\")\n",
    "        print(f\"  Panel snapshot iteration: {data['panel_snapshot_iter']}\")\n",
    "        print(f\"  Iterations tracked: {len(data['iteration_data'])}\")\n",
    "        return data\n",
    "    elif all_seeds:\n",
    "        data = all_seeds[0]\n",
    "        print(f\"Loaded unified Figure 2: {exp_dir.name}\")\n",
    "        print(f\"  Seed: {data['seed']}\")\n",
    "        print(f\"  Panel snapshot iteration: {data['panel_snapshot_iter']}\")\n",
    "        print(f\"  Iterations tracked: {len(data['iteration_data'])}\")\n",
    "        return data\n",
    "    \n",
    "    unified_files = list(exp_dir.glob(\"figure2_unified_*.json\"))\n",
    "    if not unified_files:\n",
    "        return None\n",
    "    \n",
    "    with open(unified_files[0]) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded unified Figure 2: {exp_dir.name}\")\n",
    "    print(f\"  Panel snapshot iteration: {data['panel_snapshot_iter']}\")\n",
    "    print(f\"  Iterations tracked: {len(data['iteration_data'])}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_unified_series(iteration_data: list, metric: str = 'abr') -> dict:\n",
    "    \"\"\"Extract metric series from unified iteration data.\"\"\"\n",
    "    iterations = [c['iteration'] for c in iteration_data]\n",
    "    \n",
    "    series = {'iteration': iterations}\n",
    "    \n",
    "    key_map = {\n",
    "        'fo_H': f'fo_H_{metric}',\n",
    "        'fa_H': f'fa_H_{metric}',\n",
    "        'fc_H': f'fc_H_{metric}',\n",
    "        'fa_DaVal': f'fa_DaVal_{metric}',\n",
    "        'bayesian': f'bayesian_{metric}',\n",
    "    }\n",
    "    \n",
    "    for new_key, data_key in key_map.items():\n",
    "        if data_key in iteration_data[0]:\n",
    "            series[new_key] = [c[data_key] for c in iteration_data]\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unified Figure 2 data (all panels from single acceptance loop)\n",
    "unified_data = load_unified_figure2()\n",
    "\n",
    "if unified_data:\n",
    "    print(\"\\n*** Using UNIFIED Figure 2 data (all panels from single loop) ***\")\n",
    "else:\n",
    "    print(\"ERROR: No unified data found. Run: python scripts/run_figure2_unified.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_2(unified_data: dict):\n",
    "    \"\"\"Plot Figure 2: Complete 5-panel visualization.\n",
    "    \n",
    "    Uses unified_data from run_figure2_unified.py which guarantees\n",
    "    all panels use the SAME holdout H, training snapshot (D_a, D_r),\n",
    "    and models f_a, f_o, f_c.\n",
    "    \"\"\"\n",
    "    if not unified_data:\n",
    "        print(\"No data available. Run: python scripts/run_figure2_unified.py\")\n",
    "        return None\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = fig.add_gridspec(2, 6, hspace=0.35, wspace=0.45)\n",
    "\n",
    "    # Panel (a): Bias in Data - bureau score x_v = -X1 distributions\n",
    "    ax_a = fig.add_subplot(gs[0, 0:2])\n",
    "    panel_a = unified_data['panel_a']\n",
    "    ref_xv = -np.array(panel_a['ref_xv'])\n",
    "    Da_xv = -np.array(panel_a['Da_xv'])\n",
    "    Dr_xv = -np.array(panel_a['Dr_xv'])\n",
    "\n",
    "    all_xv = np.concatenate([ref_xv, Da_xv, Dr_xv])\n",
    "    x_min, x_max = all_xv.min(), all_xv.max()\n",
    "    x_grid = np.linspace(x_min, x_max, 400)\n",
    "\n",
    "    for data, label, color in [\n",
    "        (ref_xv, 'Population (H)', 'gray'),\n",
    "        (Da_xv, 'Accepts', 'blue'),\n",
    "        (Dr_xv, 'Rejects', 'red'),\n",
    "    ]:\n",
    "        kde = gaussian_kde(data, bw_method='scott')\n",
    "        density = kde(x_grid)\n",
    "        ax_a.plot(x_grid, density, color=color, linewidth=2, label=label)\n",
    "        ax_a.fill_between(x_grid, density, alpha=0.3, color=color)\n",
    "\n",
    "    ax_a.set_xlabel('Bureau score $x_v$ (higher = better)')\n",
    "    ax_a.set_ylabel('Density')\n",
    "    ax_a.set_title('(a) Bias in Data')\n",
    "    ax_a.legend()\n",
    "\n",
    "    # Panel (b): Bias in Model - LR surrogate coefficients\n",
    "    ax_b = fig.add_subplot(gs[0, 2:4])\n",
    "    panel_b = unified_data['panel_b']\n",
    "    feature_names = panel_b['feature_names']\n",
    "    \n",
    "    accepts_coefs = np.array(panel_b['fa']['coefs'])\n",
    "    oracle_coefs = np.array(panel_b['fo']['coefs'])\n",
    "    basl_coefs = np.array(panel_b['fc']['coefs'])\n",
    "    \n",
    "    print(f\"Panel (b) RÂ² values: fa={panel_b['fa']['r2']:.3f}, fo={panel_b['fo']['r2']:.3f}, fc={panel_b['fc']['r2']:.3f}\")\n",
    "\n",
    "    def normalize_coefs_paper(coefs):\n",
    "        mags = np.abs(coefs)\n",
    "        total = mags.sum()\n",
    "        return mags / total if total > 0 else mags\n",
    "    \n",
    "    accepts_coefs_norm = normalize_coefs_paper(accepts_coefs)\n",
    "    oracle_coefs_norm = normalize_coefs_paper(oracle_coefs)\n",
    "    basl_coefs_norm = normalize_coefs_paper(basl_coefs)\n",
    "\n",
    "    x_pos = np.arange(len(feature_names))\n",
    "    width = 0.25\n",
    "\n",
    "    ax_b.bar(x_pos - width, accepts_coefs_norm, width,\n",
    "             label='Accepts-only (fa)', alpha=0.7, color='red')\n",
    "    ax_b.bar(x_pos, oracle_coefs_norm, width,\n",
    "             label='Oracle (fo)', alpha=0.7, color='green')\n",
    "    ax_b.bar(x_pos + width, basl_coefs_norm, width,\n",
    "             label='BASL (fc)', alpha=0.7, color='blue')\n",
    "\n",
    "    ax_b.set_xlabel('Coefficient')\n",
    "    ax_b.set_ylabel('Normalized coefficient magnitude')\n",
    "    ax_b.set_title('(b) Bias in Model (LR surrogate on XGB)')\n",
    "    ax_b.set_xticks(x_pos)\n",
    "    ax_b.set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "    ax_b.legend()\n",
    "\n",
    "    # Panel (c): Bias in Predictions - P(BAD) distributions with reflection KDE\n",
    "    ax_c = fig.add_subplot(gs[0, 4:6])\n",
    "    panel_c = unified_data['panel_c']\n",
    "    x_grid = np.linspace(0, 1, 1024)\n",
    "\n",
    "    for scores, label, color in [\n",
    "        (panel_c['fa_scores'], 'Accepts-only (fa)', 'red'),\n",
    "        (panel_c['fo_scores'], 'Oracle (fo)', 'green'),\n",
    "        (panel_c['fc_scores'], 'BASL (fc)', 'blue'),\n",
    "    ]:\n",
    "        scores_arr = np.array(scores)\n",
    "        density = reflected_kde_density(scores_arr, x_grid, bw_method='scott')\n",
    "        ax_c.plot(x_grid, density, color=color, linewidth=2, label=label)\n",
    "        ax_c.fill_between(x_grid, density, alpha=0.3, color=color)\n",
    "\n",
    "    ax_c.set_xlabel('Predicted P(BAD)')\n",
    "    ax_c.set_ylabel('Density')\n",
    "    ax_c.set_title('(c) Bias in Predictions')\n",
    "    ax_c.legend()\n",
    "    ax_c.set_xlim(0, 1)\n",
    "\n",
    "    # Panel (d): Impact on Evaluation - Bayesian vs Accepts-only\n",
    "    ax_d = fig.add_subplot(gs[1, 0:3])\n",
    "    series = extract_unified_series(unified_data['iteration_data'], 'abr')\n",
    "    \n",
    "    # Filter out iteration 0 (outlier)\n",
    "    mask = [i > 0 for i in series['iteration']]\n",
    "    iterations = [v for v, m in zip(series['iteration'], mask) if m]\n",
    "    fa_H = [v for v, m in zip(series['fa_H'], mask) if m]\n",
    "    fa_DaVal = [v for v, m in zip(series['fa_DaVal'], mask) if m]\n",
    "    bayesian = [v for v, m in zip(series['bayesian'], mask) if m]\n",
    "    \n",
    "    ax_d.plot(iterations, fa_H, 'k-', linewidth=2, label='Oracle (f_a on H)')\n",
    "    ax_d.plot(iterations, fa_DaVal, 'r-', linewidth=2, label='Accepts-only (f_a on D_a_val)')\n",
    "    ax_d.plot(iterations, bayesian, 'b-', linewidth=2, label='Bayesian')\n",
    "\n",
    "    ax_d.set_xlabel('Acceptance Loop Iteration')\n",
    "    ax_d.set_ylabel('ABR (Average Bad Rate)')\n",
    "    ax_d.set_title('(d) Impact on Evaluation: Bayesian vs Accepts-only')\n",
    "    ax_d.legend(loc='best')\n",
    "\n",
    "    all_values = fa_H + fa_DaVal + bayesian\n",
    "    y_min = max(0, min(all_values) - 0.1 * (max(all_values) - min(all_values)))\n",
    "    y_max = max(all_values) + 0.1 * (max(all_values) - min(all_values))\n",
    "    ax_d.set_ylim(y_min, y_max)\n",
    "    ax_d.grid(True, alpha=0.3)\n",
    "\n",
    "    # Panel (e): Impact on Training - BASL convergence\n",
    "    ax_e = fig.add_subplot(gs[1, 3:6])\n",
    "    \n",
    "    fo_H = [v for v, m in zip(series['fo_H'], mask) if m]\n",
    "    fc_H = [v for v, m in zip(series['fc_H'], mask) if m]\n",
    "    \n",
    "    ax_e.plot(iterations, fo_H, 'g-', linewidth=2, label='Oracle (fo)')\n",
    "    ax_e.plot(iterations, fa_H, 'r-', linewidth=2, label='Accepts-only (fa)')\n",
    "    ax_e.plot(iterations, fc_H, 'b-', linewidth=2, label='BASL (fc)')\n",
    "    \n",
    "    print(f\"Panel (e) fa_H ABR: {fa_H[0]:.4f} -> {fa_H[-1]:.4f}\")\n",
    "    print(f\"Panel (e) fc_H ABR: {fc_H[0]:.4f} -> {fc_H[-1]:.4f}\")\n",
    "\n",
    "    ax_e.set_xlabel('Iteration')\n",
    "    ax_e.set_ylabel('ABR')\n",
    "    ax_e.set_title('(e) Impact on Training: BASL vs Accepts-only')\n",
    "    ax_e.legend(loc='best', fontsize=8)\n",
    "\n",
    "    all_values = fo_H + fa_H + fc_H\n",
    "    y_min = max(0, min(all_values) - 0.1 * (max(all_values) - min(all_values)))\n",
    "    y_max = max(all_values) + 0.1 * (max(all_values) - min(all_values))\n",
    "    ax_e.set_ylim(y_min, y_max)\n",
    "    ax_e.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.text(0.99, 0.01, \"Data: Unified (single AcceptanceLoop)\", \n",
    "             ha='right', va='bottom', fontsize=8, style='italic')\n",
    "\n",
    "    plt.suptitle('Figure 2: Loss Due to Sampling Bias', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Plot Figure 2\n",
    "fig2 = plot_figure_2(unified_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
